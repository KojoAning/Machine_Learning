{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Object detection Using Efficientdet_d7_coco_tpu-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neccessary libraries\n",
    "\n",
    "import tensorflow as tf \n",
    "import cv2 as cv \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\XPRESS\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\core\\lambda_layer.py:297: UserWarning: google3.third_party.tensorflow.python.ops.nn_impl is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(config, custom_objects,\n",
      "c:\\Users\\XPRESS\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\core\\lambda_layer.py:297: UserWarning: google3.third_party.tensorflow_models.object_detection.utils.bifpn_utils is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(config, custom_objects,\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_130857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___38449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_145024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_99017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_139687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_125520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_101605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "#load tfod model\n",
    "model_path = \"efficientdet_d2_coco17_tpu-32/saved_model\"\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the labels of the detection \n",
    "\n",
    "with open('coco.names','r') as f:\n",
    "    names = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483 215\n",
      "[250.52084787 171.17351808  30.37239   ]\n",
      "632 505\n",
      "[186.2175476  237.25059412 158.20887695]\n",
      "554 553\n",
      "[ 18.88660286 233.13760481 108.12277897]\n",
      "150 365\n",
      "[ 53.01097789 241.00170779 240.82541371]\n",
      "845 283\n",
      "[ 87.55579706 218.85096303  45.31812426]\n",
      "432 275\n",
      "[131.52089602 181.377476   242.72425724]\n",
      "256 287\n",
      "[134.52701088 136.5625505   80.49996573]\n",
      "196 290\n",
      "[ 11.26860579  56.00257969 196.16554495]\n",
      "555 241\n",
      "[174.68950385  88.65591257 101.33289721]\n",
      "450 424\n",
      "[ 75.05697372  21.03287403 220.11388906]\n",
      "455 432\n",
      "[106.06572947  32.07217088 174.33435241]\n",
      "838 245\n",
      "[41.61317206 25.25984111 14.22836018]\n",
      "734 344\n",
      "[243.45163362  76.81146131   5.39488623]\n"
     ]
    }
   ],
   "source": [
    "img =cv.imread(r\"crosswalk-featured.jpg\")\n",
    "tensorimg = cv.cvtColor(img,cv.COLOR_BGR2RGB)  #convert BGR image to RGB image\n",
    "tensorimg = tf.convert_to_tensor(tensorimg.copy(),dtype=tf.uint8) #convert image to tensorflw tensor\n",
    "tensorimg = tensorimg[tf.newaxis,...] #expand dimensions \n",
    "\n",
    "detection = model(tensorimg)\n",
    "detection_boxes = detection[\"detection_boxes\"][0].numpy()\n",
    "detection_classes = detection[\"detection_classes\"][0].numpy().astype(np.int32)\n",
    "detection_scores = detection[\"detection_scores\"][0].numpy()\n",
    "\n",
    "\n",
    "\n",
    "random_color = np.random.uniform(low=0,high=255,size=(80,3))\n",
    "\n",
    "bboxIdx = tf.image.non_max_suppression(detection_boxes,detection_scores,max_output_size=50,iou_threshold=0.5,score_threshold=0.5)\n",
    "\n",
    "\n",
    "#function to create bounding box\n",
    "\n",
    "def create_bbox(image):\n",
    "    imH,imW,imC = image.shape\n",
    "    for i in bboxIdx:\n",
    "        bbox = tuple(detection_boxes[i].tolist())\n",
    "        classname = detection_classes[i]\n",
    "        classname = names[classname-1]\n",
    "        ymin,xmin,ymax,xmax =bbox\n",
    "        ymin,xmin,ymax,xmax = (ymin*imH,xmin*imW,ymax*imH,xmax*imW)\n",
    "        ymin = int(ymin)\n",
    "        xmin = int(xmin)\n",
    "        ymax = int(ymax)\n",
    "        xmax = int(xmax)\n",
    "        \n",
    "        # print(ymin,ymax,xmin,xmax)\n",
    "        center1 = int((xmin+xmax)/2)\n",
    "        center2 = int((ymin+ymax)/2)\n",
    "        center3 = np.random.randint(xmax/2,xmax)\n",
    "        center4 = np.random.randint(ymin,ymax)\n",
    "        center5 = np.random.randint(ymin,ymax)\n",
    "    \n",
    "        print(center3,center4)\n",
    "        if (center3-center4) < 200:\n",
    "            center3 += 100\n",
    "            center4 += 100\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        color =random_color[i]\n",
    "        print(color)\n",
    "    \n",
    "        cv.rectangle(image,(xmin,ymin),(xmax,ymax),(color),1)\n",
    "        cv.line(image,(xmin,ymin),(xmin+20,ymin),(color),3)\n",
    "        cv.line(image,(xmin,ymin),(xmin,ymin+20),(color),3)\n",
    "        cv.line(image,(xmax-20,ymin),(xmax,ymin),(color),3)\n",
    "        cv.line(image,(xmax,ymin),(xmax,ymin+20),(color),3)\n",
    "        cv.line(image,(xmax,ymax),(xmax-20,ymax),(color),3)\n",
    "        cv.line(image,(xmax,ymax-20),(xmax,ymax),(color),3)\n",
    "        cv.line(image,(xmin+20,ymax),(xmin,ymax),(color),3)\n",
    "        cv.line(image,(xmin,ymax-20),(xmin,ymax),(color),3)\n",
    "        cv.putText(image,(classname.upper()),(xmin,ymin-5),cv.FONT_HERSHEY_PLAIN,1.0,(color),2)\n",
    "\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image = create_bbox(img)\n",
    "cv.imshow(\"img\",image)\n",
    "cv.imwrite(\"testedimage.jpg\",image)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting objects from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"car_image.gif\"\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "   \n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "result = cv.VideoWriter('Output.mp4', \n",
    "                         cv.VideoWriter_fourcc(*'VP90'),\n",
    "                         10, size)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret ,img = cap.read()\n",
    "    imH ,imW ,ImC = img.shape\n",
    "    \n",
    "    frame  = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "    tensorimage = tf.convert_to_tensor(frame.copy(),dtype=tf.uint8)\n",
    "    tensorimage = tensorimage[tf.newaxis,...]\n",
    "    \n",
    "    video_detection = model(tensorimage)\n",
    "\n",
    "    # print(video_detection)\n",
    "\n",
    "    bbox = video_detection['detection_boxes'][0].numpy()\n",
    "    scores = video_detection['detection_scores'][0].numpy()\n",
    "    classnames = video_detection['detection_classes'][0].numpy().astype(np.int32)\n",
    "\n",
    "    bboxindex = tf.image.non_max_suppression(bbox,scores,max_output_size=50,iou_threshold=0.5,score_threshold=0.5)\n",
    "\n",
    "    for i in bboxindex:\n",
    "        box = tuple(bbox[i].tolist())\n",
    "        ymin ,xmin,ymax,xmax = box\n",
    "        ymin,xmin,ymax,xmax = (ymin*imH,xmin*imW,ymax*imH,xmax*imW)\n",
    "        ymin = int(ymin)\n",
    "        ymax = int(ymax)\n",
    "        xmin = int(xmin)\n",
    "        xmax = int(xmax)\n",
    "        classname = classnames[i]\n",
    "        classes = names[classname-1]\n",
    "\n",
    "\n",
    "        cv.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),thickness=2)\n",
    "        cv.putText(img,classes,(xmin,ymin),cv.FONT_HERSHEY_COMPLEX,1,(255,255,67),1)\n",
    "\n",
    "    result.write(img)\n",
    "    cv.imshow('frame',img)\n",
    "    if cv.waitKey(1) & 0xFF == ord('e'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4710678d38da463ebf9aaba594cfd4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Video, Image\n",
    "new_ = Video.from_file('output.mp4',play=True)\n",
    "new_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6044cbfacf5d5106cab388b0401c1f1c68efa341509c60f9f5664fb81ce626f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
