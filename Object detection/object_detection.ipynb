{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Object detection Using Efficientdet_d7_coco_tpu-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neccessary libraries\n",
    "\n",
    "import tensorflow as tf \n",
    "import cv2 as cv \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPRESS\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\core\\lambda_layer.py:297: UserWarning: google3.third_party.tensorflow.python.ops.nn_impl is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(config, custom_objects,\n",
      "C:\\Users\\XPRESS\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\core\\lambda_layer.py:297: UserWarning: google3.third_party.tensorflow_models.object_detection.utils.bifpn_utils is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(config, custom_objects,\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_130857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___38449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_145024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_99017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_139687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_125520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_101605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "#load tfod model\n",
    "model_path = \"efficientdet_d2_coco17_tpu-32/saved_model\"\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the labels of the detection \n",
    "\n",
    "with open('coco.names','r') as f:\n",
    "    names = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497 410\n",
      "[228.87933314 236.4999965  124.85913388]\n",
      "973 196\n",
      "[251.70585696 174.78571049  91.77112615]\n",
      "405 276\n",
      "[183.43198739  47.75261664 158.27050987]\n",
      "176 478\n",
      "[106.50791224  77.01792756  29.91212854]\n",
      "992 248\n",
      "[54.9536257  99.38343364 54.19087913]\n",
      "609 258\n",
      "[213.5113928  249.98298518 155.47401067]\n",
      "272 265\n",
      "[172.15861131 136.64595591 150.92575178]\n",
      "184 262\n",
      "[161.0933345  119.70584127 227.09603176]\n",
      "825 251\n",
      "[206.23108502   1.62212549 178.29777162]\n",
      "309 463\n",
      "[  7.95900561 227.65643781 188.15348327]\n",
      "830 417\n",
      "[ 88.58050786  36.46899279 233.03215589]\n",
      "829 266\n",
      "[181.30643023  45.37177809  63.65503235]\n",
      "443 382\n",
      "[160.9905954  176.10446162 193.40676333]\n"
     ]
    }
   ],
   "source": [
    "img =cv.imread(r\"crosswalk-featured.jpg\")\n",
    "tensorimg = cv.cvtColor(img,cv.COLOR_BGR2RGB)  #convert BGR image to RGB image\n",
    "tensorimg = tf.convert_to_tensor(tensorimg.copy(),dtype=tf.uint8) #convert image to tensorflw tensor\n",
    "tensorimg = tensorimg[tf.newaxis,...] #expand dimensions \n",
    "\n",
    "detection = model(tensorimg)\n",
    "detection_boxes = detection[\"detection_boxes\"][0].numpy()\n",
    "detection_classes = detection[\"detection_classes\"][0].numpy().astype(np.int32)\n",
    "detection_scores = detection[\"detection_scores\"][0].numpy()\n",
    "\n",
    "\n",
    "\n",
    "random_color = np.random.uniform(low=0,high=255,size=(80,3))\n",
    "\n",
    "bboxIdx = tf.image.non_max_suppression(detection_boxes,detection_scores,max_output_size=50,iou_threshold=0.5,score_threshold=0.5)\n",
    "\n",
    "\n",
    "#function to create bounding box\n",
    "\n",
    "def create_bbox(image):\n",
    "    imH,imW,imC = image.shape\n",
    "    for i in bboxIdx:\n",
    "        bbox = tuple(detection_boxes[i].tolist())\n",
    "        classname = detection_classes[i]\n",
    "        classname = names[classname-1]\n",
    "        ymin,xmin,ymax,xmax =bbox\n",
    "        ymin,xmin,ymax,xmax = (ymin*imH,xmin*imW,ymax*imH,xmax*imW)\n",
    "        ymin = int(ymin)\n",
    "        xmin = int(xmin)\n",
    "        ymax = int(ymax)\n",
    "        xmax = int(xmax)\n",
    "        \n",
    "        # print(ymin,ymax,xmin,xmax)\n",
    "        center1 = int((xmin+xmax)/2)\n",
    "        center2 = int((ymin+ymax)/2)\n",
    "        center3 = np.random.randint(xmax/2,xmax)\n",
    "        center4 = np.random.randint(ymin,ymax)\n",
    "        center5 = np.random.randint(ymin,ymax)\n",
    "    \n",
    "        print(center3,center4)\n",
    "        if (center3-center4) < 200:\n",
    "            center3 += 100\n",
    "            center4 += 100\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        color =random_color[i]\n",
    "        print(color)\n",
    "    \n",
    "        cv.rectangle(image,(xmin,ymin),(xmax,ymax),(color),1)\n",
    "        cv.line(image,(xmin,ymin),(xmin+20,ymin),(color),3)\n",
    "        cv.line(image,(xmin,ymin),(xmin,ymin+20),(color),3)\n",
    "        cv.line(image,(xmax-20,ymin),(xmax,ymin),(color),3)\n",
    "        cv.line(image,(xmax,ymin),(xmax,ymin+20),(color),3)\n",
    "        cv.line(image,(xmax,ymax),(xmax-20,ymax),(color),3)\n",
    "        cv.line(image,(xmax,ymax-20),(xmax,ymax),(color),3)\n",
    "        cv.line(image,(xmin+20,ymax),(xmin,ymax),(color),3)\n",
    "        cv.line(image,(xmin,ymax-20),(xmin,ymax),(color),3)\n",
    "        cv.putText(image,(classname.upper()),(xmin,ymin-5),cv.FONT_HERSHEY_PLAIN,1.0,(color),2)\n",
    "\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image = create_bbox(img)\n",
    "cv.imshow(\"img\",image)\n",
    "cv.imwrite(\"testedimage.jpg\",image)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting objects from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"car_image.gif\"\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "   \n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "result = cv.VideoWriter('Output.mp4', \n",
    "                         cv.VideoWriter_fourcc(*'FLAC'),\n",
    "                         10, size)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret ,img = cap.read()\n",
    "    imH ,imW ,ImC = img.shape\n",
    "    \n",
    "    frame  = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "    tensorimage = tf.convert_to_tensor(frame.copy(),dtype=tf.uint8)\n",
    "    tensorimage = tensorimage[tf.newaxis,...]\n",
    "    \n",
    "    video_detection = model(tensorimage)\n",
    "\n",
    "    # print(video_detection)\n",
    "\n",
    "    bbox = video_detection['detection_boxes'][0].numpy()\n",
    "    scores = video_detection['detection_scores'][0].numpy()\n",
    "    classnames = video_detection['detection_classes'][0].numpy().astype(np.int32)\n",
    "\n",
    "    bboxindex = tf.image.non_max_suppression(bbox,scores,max_output_size=50,iou_threshold=0.5,score_threshold=0.5)\n",
    "\n",
    "    for i in bboxindex:\n",
    "        box = tuple(bbox[i].tolist())\n",
    "        ymin ,xmin,ymax,xmax = box\n",
    "        ymin,xmin,ymax,xmax = (ymin*imH,xmin*imW,ymax*imH,xmax*imW)\n",
    "        ymin = int(ymin)\n",
    "        ymax = int(ymax)\n",
    "        xmin = int(xmin)\n",
    "        xmax = int(xmax)\n",
    "        classname = classnames[i]\n",
    "        classes = names[classname-1]\n",
    "\n",
    "\n",
    "        cv.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),thickness=2)\n",
    "        cv.putText(img,classes,(xmin,ymin),cv.FONT_HERSHEY_COMPLEX,1,(255,255,67),1)\n",
    "\n",
    "    result.write(img)\n",
    "    cv.imshow('frame',img)\n",
    "    if cv.waitKey(1) & 0xFF == ord('e'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec8d1cb91a14a2db7ef5545f3c7be89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00\\x1cftypisom\\x00\\x00\\x02\\x00isomiso2mp41\\x00\\x00\\x00\\x08free\\x00\\x08\\xc0\\x8fmdat\\x82…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('tensorflow-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6044cbfacf5d5106cab388b0401c1f1c68efa341509c60f9f5664fb81ce626f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
